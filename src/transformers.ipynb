{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d54d09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994666c3",
   "metadata": {},
   "source": [
    "# Transformers!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ae094",
   "metadata": {},
   "source": [
    "# Let's Start with a Basic Bigram Model First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3933cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/more.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    words = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6662417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd0d5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(words)))\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "796f048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "stoi = {s:i for i, s in enumerate(vocab)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "encode = lambda x: [stoi[let] for let in x]\n",
    "decode = lambda x: ''.join([itos[num] for num in x])\n",
    "\n",
    "print(decode(encode(\"Hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3503a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(encode(words), dtype=torch.long)\n",
    "\n",
    "n = int(0.9 * len(x))\n",
    "x_train = x[:n]\n",
    "x_test = x[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c92492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 8\n",
    "\n",
    "def get_batch(split, batch_size=4):\n",
    "    data = x_train if split == 'train' else x_test\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    \n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "358819ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'-epO$bLytCqlIPbJjcJUyFDmFH?n,PWCaDpS!hcf,HJYbIPtje'FHdfyUSf\n",
      "U: SgyGyvTCw&RZiIrW,DbJYIaZMV3Dr-p,?nHR\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        logits = self.embed(x) # (B, T) --> (B, T, C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "    \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :] # (B, T, C) --> (B, C)\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            new_idx = torch.multinomial(probs, num_samples=1, replacement=True) # (B, 1)\n",
    "            idx = torch.cat((idx, new_idx), 1) # (B, T+1)\n",
    "\n",
    "\n",
    "        return idx\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "# xb, yb = get_batch('train')\n",
    "\n",
    "# print(xb.shape, yb.shape)\n",
    "\n",
    "# out, losses = model(xb, yb)\n",
    "\n",
    "# print(out.shape)\n",
    "# print(losses)\n",
    "\n",
    "out = model.generate(torch.zeros(1, 1, dtype=torch.long), max_new_tokens=100)\n",
    "\n",
    "print(decode(out[0].tolist()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5193c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.347870826721191\n",
      "4.3771209716796875\n",
      "4.391764163970947\n",
      "4.356290340423584\n",
      "4.235705375671387\n",
      "4.277715682983398\n",
      "4.366168022155762\n",
      "4.297664165496826\n",
      "4.2857208251953125\n",
      "4.288779258728027\n",
      "4.395979881286621\n",
      "4.346039295196533\n",
      "4.2566752433776855\n",
      "4.280689239501953\n",
      "4.231051445007324\n",
      "4.421597957611084\n",
      "4.360658168792725\n",
      "4.310080051422119\n",
      "4.24181604385376\n",
      "4.304861068725586\n",
      "4.312815189361572\n",
      "4.366235733032227\n",
      "4.301136493682861\n",
      "4.310800552368164\n",
      "4.302674293518066\n",
      "4.243205547332764\n",
      "4.35451602935791\n",
      "4.279906272888184\n",
      "4.303950786590576\n",
      "4.306549072265625\n",
      "4.2576680183410645\n",
      "4.297036647796631\n",
      "4.31735897064209\n",
      "4.293255805969238\n",
      "4.301681995391846\n",
      "4.308203220367432\n",
      "4.283802509307861\n",
      "4.322900295257568\n",
      "4.272191524505615\n",
      "4.252161979675293\n",
      "4.32408332824707\n",
      "4.350278377532959\n",
      "4.347704887390137\n",
      "4.300105571746826\n",
      "4.279798984527588\n",
      "4.2316670417785645\n",
      "4.27830696105957\n",
      "4.292902946472168\n",
      "4.256102085113525\n",
      "4.306896209716797\n",
      "4.308385848999023\n",
      "4.3075270652771\n",
      "4.259124279022217\n",
      "4.246212959289551\n",
      "4.281569004058838\n",
      "4.290284156799316\n",
      "4.268711566925049\n",
      "4.334146022796631\n",
      "4.229259967803955\n",
      "4.290399074554443\n",
      "4.281682014465332\n",
      "4.23842716217041\n",
      "4.250244140625\n",
      "4.159036159515381\n",
      "4.250576496124268\n",
      "4.197785377502441\n",
      "4.262567520141602\n",
      "4.226924896240234\n",
      "4.230727195739746\n",
      "4.272292137145996\n",
      "4.328956604003906\n",
      "4.340478897094727\n",
      "4.223013401031494\n",
      "4.155689239501953\n",
      "4.299757480621338\n",
      "4.253998756408691\n",
      "4.234429359436035\n",
      "4.244701862335205\n",
      "4.342171669006348\n",
      "4.173316955566406\n",
      "4.205939292907715\n",
      "4.196370601654053\n",
      "4.205755233764648\n",
      "4.253345489501953\n",
      "4.297612190246582\n",
      "4.115794658660889\n",
      "4.182126998901367\n",
      "4.265505790710449\n",
      "4.204242706298828\n",
      "4.218574047088623\n",
      "4.274666786193848\n",
      "4.306815147399902\n",
      "4.262912750244141\n",
      "4.194375991821289\n",
      "4.248504638671875\n",
      "4.294712543487549\n",
      "4.222314834594727\n",
      "4.243561267852783\n",
      "4.211316108703613\n",
      "4.204521179199219\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    xb, yb = get_batch('train', batch_size=batch_size)\n",
    "    logits, ep_loss = model(xb, yb) # (B*T, C) | (B*T)\n",
    "    \n",
    "    print(ep_loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    ep_loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cae9ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DJd oel wKnvi?n.kL?neh:!w\n",
      "GSj$KnIHxAQmG&El3jj,ptNUY$hcT&th.ZMtfCMiCQDJDUsN;.OBhCE3HJKyRZ\n",
      "aCa kIbDnS:cwx!I'x.pYV  syKy.eWka,fCUyUjVAMaqWayfUyKvIfnxwLzitfWyvSP-kVoWi;!D3XBbzwrfinviV3\n",
      "3Mrer;wrczwBtpmuCeBbzaHZWs3qDJXmM&MF,EPBNUI FZW-b\n",
      ",VQPdUkIvg;Z?RRwaAo-w?MAF3Klmy3gUUH\n",
      "UytjhXFMdq-exE:eyvuVbK!utKZ-MNKVqoqXUVXb\n",
      "cbBYn..ffiV\n",
      "MzulOU!wOsTdaU.u ?jQTIugscGFjQKoaRMYa3w?nFDCv!;kIxxMjZ\n",
      "ejeW;xwkjyQD zCNkoVc.\n",
      "MnX3:Ie$nqxBkfSCaT3n$'wmu,.DWiThqEUmXTCxa:&;neB;V$\n",
      "MFEzuH?ZHo&pYzUWiSvO-w&QzuA sss-mlsngJ$KXS:XrfaVPzBy\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(torch.zeros(1, 1, dtype=torch.long), max_new_tokens=500)\n",
    "\n",
    "print(decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212f685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
